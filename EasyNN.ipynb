{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EasyNN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scaverod/EasyNN/blob/master/EasyNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dnxPFqLhTB1",
        "colab_type": "text"
      },
      "source": [
        "# Easy Neural Network\n",
        "\n",
        "Este cuaderno permite la construcción de redes de neuronas de forma sencilla. Basta con determinar y configurar los diferentes elementos que componen la red. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbI1pgpyrgQm",
        "colab_type": "text"
      },
      "source": [
        "## 1. Preparación del entorno\n",
        "Para el diseño de una red de neuronas artificiales haremos uso de Tensorflow y Keras. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFWn-gbBrmMP",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Carga de librerías\n",
        "\n",
        "**TensorFlow** es una biblioteca implementada por Google para sus aplicaciones de aprendizaje automático y las redes neuronales profundas.  TensorFlow es una librería para ejecutar operaciones matemáticas, es capaz ejecutar de forma rápida y eficiente operaciones matemáticas representadas cuya entrada y salida son un vector multidimensional (o tensor) de datos.\n",
        "\n",
        "Por otro lado, **Keras** es una librería de redes neuronales desarrollada por François Chollet (entre otros), un ingeniero de Google. Keras es una abstracción para la creación de modelos de aprendizaje que opera con Tensorflow. \n",
        "\n",
        "En este trabajo haremos uso de la versión 2 te Tensorflow la cual acaba acaba de ser publicada. Por defecto en las máquinas de Google Colabn no está instalada por lo tanto será lo primero que haremos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JtX9_NchTn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow-gpu==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kAt1xgTIeZJ",
        "colab_type": "text"
      },
      "source": [
        "Ahora importaremos todas las librerías necesarias para el desarrollo de esta práctica:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VymTUPlphhbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"Tensorflow version: \"+tf.__version__)\n",
        "print(\"Keras version: \"+keras.__version__)\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm import tqdm\n",
        "from time import gmtime, strftime\n",
        "from enum import Enum\n",
        "import time \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Google file system\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "print(\"Librerías cargadas correctamente\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGUspSaGgmts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ATT_FILE = \"/gdrive/My Drive/\"\n",
        "LABEL_FILE = \"/gdrive/My Drive/\"\n",
        "MODEL_PATH = \"/gdrive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKx8fZm6rxDF",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Definición de funciones útiles\n",
        "En esta sección vamos a implementar variables, funciones y clases que nos serán útiles a lo largo de este trabajo:\n",
        "* `SEED`: semilla que permite controlar la aleatoriedad de manera que los experimentos sean repetibles.  \n",
        "* `save_model`: permite guardar un modelo de una red de neuronas\n",
        "* `load_model`: permite cargar un modelo de una red de neuronas\n",
        "* `ActivationFunction`:\n",
        "* TODO:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whh-EpvYcuSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ivgQODNiE3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model, name=strftime(\"%Y-%m-%d\", gmtime())):\n",
        "    \"\"\"Save a Keras model with a specific name\"\"\"\n",
        "    model.save(MODEL_PATH+name)\n",
        "    print(\"Model saved\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaS3Arn_mBwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(model):\n",
        "  \"\"\"Return a specific keras model.\"\"\"\n",
        "  return keras.models.load_model(MODEL_PATH+model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu-0_ZOUXA89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ActivationFunction(Enum):\n",
        "  \"\"\" https://keras.io/activations/ \"\"\"\n",
        "  ELU = \"elu\"\n",
        "  SOFTMAX = \"softmax\"\n",
        "  SELU = \"selu\"\n",
        "  SOFTPLUS = \"softplus\"\n",
        "  SOFTSIGN = \"softsign\"\n",
        "  RELU = \"relu\"\n",
        "  TANH = \"tanh\"\n",
        "  SIGMOID = \"sigmoid\"\n",
        "  H_SIGMOID = \"hard_sigmoid\"\n",
        "  EXPONENTIAL = \"exponential\"\n",
        "  LINEAR = \"linear\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA_LjZyNZjml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Option(Enum):\n",
        "  YES = True\n",
        "  NO = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJYavq7FaNsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Initializers(Enum):\n",
        "  ZEROS = keras.initializers.Zeros()\n",
        "  ONES = keras.initializers.Ones()\n",
        "  CONSTANT = keras.initializers.Constant(value=0)\n",
        "  RANDOMNORMAL = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=SEED)\n",
        "  RANDOMUNIFORM = keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=SEED)\n",
        "  TRUNCATEDNORMAL = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=SEED)\n",
        "  ORTHOGONAL = keras.initializers.Orthogonal(gain=1.0, seed=SEED)\n",
        "  IDENTITY = keras.initializers.Identity(gain=1.0)\n",
        "  LECUN_UNIFORM = keras.initializers.lecun_uniform(seed=SEED)\n",
        "  GLOROT_NORMAL = keras.initializers.glorot_normal(seed=SEED)\n",
        "  GLOROT_UNIFORM = keras.initializers.glorot_uniform(seed=SEED)\n",
        "  HE_NORMAL = keras.initializers.he_normal(seed=SEED)\n",
        "  HE_UNIFORM = keras.initializers.he_uniform(seed=SEED)\n",
        "  LECUN_NORMAL = keras.initializers.lecun_normal(seed=SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS53B3erNJKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizers(Enum):\n",
        "  SGD = 0\n",
        "  RMSPROP = 1\n",
        "  ADAGRAD = 2\n",
        "  ADADELTA = 3\n",
        "  ADAM = 4\n",
        "  ADAMAX = 5 \n",
        "  NADAM = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIPXJuwGWbEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ask(parameter, default_value):\n",
        "  try:\n",
        "    return float(input(\"Please enter the \"+  parameter + \" : \"))\n",
        "  except ValueError:\n",
        "       print(\"Oops!  That was no valid input, \"+  parameter + \" will be \" + str(default_value))\n",
        "       return default_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5HLWD-9nx3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ask_bool(parameter, default_value):\n",
        "  s =input(\"Please enter the \"+  parameter + \" : \")\n",
        "  if s.lower() in ['true', '1', 't', 'y', 'yes', 'yeah', 'yup', 'certainly', 'uh-huh']:\n",
        "    return True\n",
        "  else:\n",
        "    print(\"Oops!  That was no valid input, \"+  parameter + \" will be \" + str(default_value))\n",
        "    return default_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IEh-LNgR6f4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def select_optimizer(optimizer):\n",
        "  if optimizer is Optimizers.SGD:\n",
        "    return keras.optimizers.SGD(learning_rate=ask(\"learning rate\", float(0.01)), momentum=ask(\"momentum\", float(0)), nesterov=ask_bool(\"nesterov\", False))\n",
        "  elif optimizer is Optimizers.RMSPROP:\n",
        "    return keras.optimizers.RMSprop(learning_rate=ask(\"learning rate\", float(0.001)), rho=ask(\"rho\", float(0.9)))\n",
        "  elif optimizer is Optimizers.ADAGRAD:\n",
        "    return keras.optimizers.Adagrad(learning_rate=ask(\"learning rate\", float(0.01)))\n",
        "  elif optimizer is Optimizers.ADADELTA:\n",
        "    return keras.optimizers.Adadelta(learning_rate=ask(\"learning rate\", float(1.0)), rho=ask(\"rho\", float(0.95)))\n",
        "  elif optimizer is Optimizers.ADAM:\n",
        "    return keras.optimizers.Adam(learning_rate=ask(\"learning rate\", float(0.001)), beta_1=ask(\"beta 1\", float(0.9)), beta_2=ask(\"beta 2\", float(0.999)), amsgrad=ask_bool(\"amsgrad\", False))\n",
        "  elif optimizer is Optimizers.ADAMAX:\n",
        "    return keras.optimizers.Adamax(learning_rate=ask(\"learning rate\", float(0.002)), beta_1=ask(\"beta 1\", float(0.9)), beta_2=ask(\"beta 2\", float(0.999)))\n",
        "  elif optimizer is Optimizers.NADAM:\n",
        "    return keras.optimizers.Nadam(learning_rate=ask(\"learning rate\", float(0.002)), beta_1=ask(\"beta 1\", float(0.9)), beta_2=ask(\"beta 2\", float(0.999)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQxJD-6MNIdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_act_fun(a_f, n_layers):\n",
        "  act_fun = []\n",
        "  if not a_f:\n",
        "    act_fun = [ActivationFunction.RELU] * n_layers\n",
        "  elif type(a_f)!=list:\n",
        "    act_fun = [a_f] * n_layers\n",
        "  elif len(a_f) > n_layers:\n",
        "    act_fun = a_f[:n_layers]\n",
        "  elif len(a_f) < n_layers:\n",
        "    act_fun = a_f + [a_f[-1]] * (n_layers-len(a_f))\n",
        "  else:\n",
        "    return a_f\n",
        "  return act_fun"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0H9uir3RJbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dropout(drp, n_layers):\n",
        "  act_fun = []\n",
        "  if not drp:\n",
        "    act_fun = [0.5] * n_layers\n",
        "  elif type(drp)!=list:\n",
        "    act_fun = [drp] * n_layers\n",
        "  elif len(drp) > n_layers:\n",
        "    act_fun = drp[:n_layers]\n",
        "  elif len(drp) < n_layers:\n",
        "    act_fun = drp + [drp[-1]] * (n_layers-len(drp))\n",
        "  else:\n",
        "    return drp\n",
        "  return act_fun"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDIKMHCUksH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_regularizer(regularizer_L1, regularizer_L2):\n",
        "  if regularizer_L1 and regularizer_L2:\n",
        "    return keras.regularizers.l1_l2(regularizer_L1, regularizer_L2)\n",
        "  elif not regularizer_L1 and not regularizer_L2:\n",
        "    return None\n",
        "  elif not regularizer_L1:\n",
        "    return keras.regularizers.l1(regularizer_L2)\n",
        "  else:\n",
        "    return keras.regularizers.l1(regularizer_L1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ewLYdLresBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_cm(y_true, y_pred, figsize=(10,10)):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
        "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "    cm_perc = cm / cm_sum.astype(float) * 100\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            c = cm[i, j]\n",
        "            p = cm_perc[i, j]\n",
        "            if i == j:\n",
        "                s = cm_sum[i]\n",
        "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "            elif c == 0:\n",
        "                annot[i, j] = ''\n",
        "            else:\n",
        "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
        "    cm.index.name = 'Actual'\n",
        "    cm.columns.name = 'Predicted'\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeHHwuwVr6KA",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 División del conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIgPov53hoDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_RATE=0.8\n",
        "\n",
        "attributes = pd.read_csv(ATT_FILE)\n",
        "label = pd.read_csv(LABEL_FILE)\n",
        "\n",
        "n_instances = attributes.shape[0]\n",
        "n_train = int(n_instances*TRAIN_RATE)\n",
        "n_dev = int((n_instances-n_train)/2)\n",
        "n_final_test = n_instances-n_train-n_dev\n",
        "\n",
        "\n",
        "x_train = attributes.values[:n_train]\n",
        "t_train = label.values[:n_train]\n",
        "\n",
        "x_dev = attributes.values[n_train:n_train+n_dev]\n",
        "t_dev = label.values[n_train:n_train+n_dev]\n",
        "\n",
        "x_final_test = attributes.values[n_train+n_dev:n_instances]\n",
        "t_final_test = label.values[n_train+n_dev:n_instances]\n",
        "\n",
        "INPUTS = x_train.shape[1]\n",
        "OUTPUTS = t_train.shape[1]\n",
        "\n",
        "print (\"x_train:\",x_train.shape)\n",
        "print (\"t_train:\",t_train.shape)\n",
        "\n",
        "print (\"x_dev:\",x_dev.shape)\n",
        "print (\"t_dev:\",t_dev.shape)\n",
        "\n",
        "print (\"x_final_test:\",x_final_test.shape)\n",
        "print (\"t_final_test:\",t_final_test.shape)\n",
        "\n",
        "print (\"INPUTS: \",INPUTS)\n",
        "print (\"OUTPUTS: \",OUTPUTS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay0iBQbPnTiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape[0] + x_dev.shape[0] + x_final_test.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSZQTHIIVkxI",
        "colab_type": "text"
      },
      "source": [
        "## 2. Definir valores de Hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCGHo_ZtVwVM",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Número de epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXQe2WvnWMvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs =1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fypmYB1CVz0M",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Tamaño del Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHaIpZZcWOms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rGAzhKOV8-E",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Arquitectura de la red\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buzgTEDdoheD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_neurons_per_hlayer = [128,64,32]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mx8l8xlWU9k",
        "colab_type": "text"
      },
      "source": [
        "### 2.4 Optimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhxSVl00WV40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = select_optimizer(Optimizers.ADAM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIATWhpqWUCE",
        "colab_type": "text"
      },
      "source": [
        "### 2.5 Función de Activación\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE4N5Nq2Y1SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = ActivationFunction.RELU\n",
        "# or one for each layer [ActivationFunction.RELU,ActivationFunction.RELU,ActivationFunction.RELU,ActivationFunction.RELU,ActivationFunction.RELU]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F63CEMmJdh8m",
        "colab_type": "text"
      },
      "source": [
        "### 2.6 Inicialización de los pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA9kf41sZJ5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel_initializer = Initializers.HE_NORMAL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSYaxmNGd6Lv",
        "colab_type": "text"
      },
      "source": [
        "### 2.7 Normalización del Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGXdqd1-eAE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalization = Option.NO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGcY0QWFfZ3t",
        "colab_type": "text"
      },
      "source": [
        "### 2.8 Regularización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8zwGX-QgEZd",
        "colab_type": "text"
      },
      "source": [
        "#### Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvuIyvAtfiaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout = Option.NO\n",
        "prob_per_hlayer = [0.05,0.02,0.01]\n",
        "# https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kznXGeogHtN",
        "colab_type": "text"
      },
      "source": [
        "#### Regularización L1 y L2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MQQQ-jXMulc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regularizer_L1 = None\n",
        "regularizer_L2 = None\n",
        "# More info: https://medium.com/datadriveninvestor/l1-l2-regularization-7f1b4fe948f2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG9UetuRwSOJ",
        "colab_type": "text"
      },
      "source": [
        "### 2.9 Mostrar trazas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4J-9HyvwcSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "verbose = Option.YES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGOXk0BygK6o",
        "colab_type": "text"
      },
      "source": [
        "## 3. Construcción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohVzPVtygRUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(model_name =\"FeedforwardNN\",\n",
        "                 n_neurons_per_hlayer=[1000, 500, 250, 75, 25],\n",
        "                 optimizer = None,\n",
        "                 verbose = Option.NO,\n",
        "                 act_fun = None,\n",
        "                 kernel_initializer=Initializers.GLOROT_UNIFORM, \n",
        "                 normalization = Option.NO,\n",
        "                 dropout = Option.NO, \n",
        "                 drop_prop = None, \n",
        "                 regularizer_L1 = None, \n",
        "                 regularizer_L2 = None):\n",
        "  \n",
        "  a_f = get_act_fun(act_fun, len(n_neurons_per_hlayer))\n",
        "  if not optimizer:   optimizer = select_optimizer(Optimizers.SGD)\n",
        "  if dropout is Option.YES: drop_prop = get_dropout(drop_prop,len(n_neurons_per_hlayer))\n",
        "  kernel_regularizer = get_regularizer(regularizer_L1, regularizer_L2)\n",
        "  if verbose.value: print(\"Creating model...\")\n",
        "  model = keras.Sequential(name=model_name)\n",
        "  if verbose.value: print(\"Model name set as: \" + model_name)\n",
        "  model.add(keras.layers.InputLayer(input_shape=(INPUTS,), batch_size=None))\n",
        "  if verbose.value: print(\"Input layer created. Number of inputs is \" + str(INPUTS))\n",
        "  for i, (neurons, act) in enumerate(zip(n_neurons_per_hlayer, a_f)):\n",
        "    if verbose.value: print(\"For layer \"+ str(i+1)+\"... \\n   \\t- Weight initializer is \" + kernel_initializer.name + \"\\n   \\t- Number of neurons is \" + str(neurons))\n",
        "    if kernel_regularizer:\n",
        "      model.add(keras.layers.Dense(neurons, kernel_initializer=kernel_initializer.value, kernel_regularizer=kernel_regularizer))\n",
        "      if verbose.value: print(\"   \\t- Kernel regularization is used. L1 is \" + str(regularizer_L1) + \" and L2 is \" + str(regularizer_L2))\n",
        "    else: \n",
        "      model.add(keras.layers.Dense(neurons, kernel_initializer=kernel_initializer.value))\n",
        "    if normalization is Option.YES : \n",
        "      model.add(tf.keras.layers.BatchNormalization())\n",
        "      if verbose.value: print(\"   \\t- Batch Normalization is used\")\n",
        "    model.add(tf.keras.layers.Activation(act.value))\n",
        "    if verbose.value: print(\"   \\t- Activation Function is \" + act.value)\n",
        "    if dropout is Option.YES : \n",
        "      model.add(tf.keras.layers.Dropout(drop_prop[i]))\n",
        "      if verbose.value: print(\"   \\t- Dropout is used with p=\" + str(drop_prop[i]))\n",
        "\n",
        "  model.add(keras.layers.Dense(OUTPUTS, activation=\"softmax\", name=\"Softmax\"))\n",
        "  if verbose.value: print(\"Output layer created. Number of outputs is \" + str(OUTPUTS))\n",
        "  model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"categorical_accuracy\"])\n",
        "  if verbose.value:\n",
        "    print(\"\\n ########## SUMMARY ##########\")\n",
        "    model.summary()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-RQoCLAggM9",
        "colab_type": "text"
      },
      "source": [
        "## 4. Entrenamiento y validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzGO0NrASMN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model(n_neurons_per_hlayer=n_neurons_per_hlayer,\n",
        "                  optimizer = optimizer,\n",
        "                  verbose = verbose,\n",
        "                  act_fun = activation,\n",
        "                  kernel_initializer=kernel_initializer, \n",
        "                  normalization = normalization,\n",
        "                  dropout = dropout, \n",
        "                  drop_prop = prob_per_hlayer, \n",
        "                  regularizer_L1 = regularizer_L1, \n",
        "                  regularizer_L2 = regularizer_L2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIaaiOPmgl_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = time.clock()\n",
        "history = model.fit(x_train, t_train, batch_size=batch_size, epochs=n_epochs, \n",
        "                     verbose=verbose.value, validation_data=(x_dev, t_dev))\n",
        "print (\"Numero de épocas \" + str(n_epochs))\n",
        "print (\"Tamaño del lote \" + str(batch_size))                       \n",
        "print (\"Tiempo necesitado \" +  \"{:.2f}\".format(time.clock() - start) + \"s.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-87RZZYFgpef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results=pd.DataFrame(history.history)\n",
        "results.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.xlabel (\"Epochs\")\n",
        "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0,1]\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI_-iJP7gwx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Error for the training set: \", (1 - results.categorical_accuracy.values[-1:][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJvwSfIxgxZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Error for the development test set: \", (1 - results.val_categorical_accuracy.values[-1:][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhg02LRXe2rw",
        "colab_type": "text"
      },
      "source": [
        "## 5. Test final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy1G498_eetC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(x_final_test, verbose=0)\n",
        "y_true=np.argmax(t_final_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbKlualkeW9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"Error for the final test set: \", (1 - accuracy_score(y_true, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3CAnRPlehGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_cm(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vc16rmQf_za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
